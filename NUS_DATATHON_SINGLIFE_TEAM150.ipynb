{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install pyarrow\n",
    "#%pip install numpy\n",
    "#%pip install scikit-learn\n",
    "#%pip install imbalanced-learn\n",
    "#%pip install matplotlib\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "filepath = \"./data/catB_train.parquet\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and KNN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data into dataframe\n",
    "df = pd.read_parquet(\"./data/catB_train.parquet\")\n",
    "\n",
    "# Convert target col to 0 or 1\n",
    "df[\"f_purchase_lh\"] = df[\"f_purchase_lh\"].fillna(0)\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "\n",
    "# Create a mask of non-NA values\n",
    "non_na_mask = numeric_cols.notna()\n",
    "\n",
    "# Initialize KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "#KNN imputation on non-NA values\n",
    "imputed_non_na = imputer.fit_transform(numeric_cols[non_na_mask])\n",
    "imputed_df = pd.DataFrame(imputed_non_na, columns=numeric_cols.columns, index=numeric_cols.index)\n",
    "\n",
    "# Replace NA values with imputed values from nearest non-NA neighbors\n",
    "for col in numeric_cols.columns:\n",
    "    df[col].fillna(imputed_df[col], inplace=True)\n",
    "\n",
    "\n",
    "# Display DataFrame after imputation\n",
    "#print(df)\n",
    "\n",
    "# Drop non-numeric cols\n",
    "non_numeric_cols = df.select_dtypes(include=[\"string\", \"object\"]).columns\n",
    "df = df.drop(columns=non_numeric_cols)\n",
    "\n",
    "y = df[\"f_purchase_lh\"]\n",
    "X = df.drop(columns=['f_purchase_lh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17992 entries, 19550 to 15795\n",
      "Data columns (total 90 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   flg_substandard                    17992 non-null  float64\n",
      " 1   flg_is_borderline_standard         17992 non-null  float64\n",
      " 2   flg_is_revised_term                17992 non-null  float64\n",
      " 3   flg_is_rental_flat                 17992 non-null  float64\n",
      " 4   flg_has_health_claim               17992 non-null  float64\n",
      " 5   flg_has_life_claim                 17992 non-null  float64\n",
      " 6   flg_gi_claim                       17992 non-null  float64\n",
      " 7   flg_is_proposal                    17992 non-null  float64\n",
      " 8   flg_with_preauthorisation          17992 non-null  float64\n",
      " 9   flg_is_returned_mail               17992 non-null  float64\n",
      " 10  is_consent_to_mail                 17992 non-null  float64\n",
      " 11  is_consent_to_email                17992 non-null  float64\n",
      " 12  is_consent_to_call                 17992 non-null  float64\n",
      " 13  is_consent_to_sms                  17992 non-null  float64\n",
      " 14  is_valid_dm                        17992 non-null  float64\n",
      " 15  is_valid_email                     17992 non-null  float64\n",
      " 16  is_housewife_retiree               17992 non-null  float64\n",
      " 17  is_sg_pr                           17992 non-null  float64\n",
      " 18  is_class_1_2                       17992 non-null  float64\n",
      " 19  is_dependent_in_at_least_1_policy  17992 non-null  float64\n",
      " 20  f_ever_declined_la                 17992 non-null  float64\n",
      " 21  hh_size                            17992 non-null  float64\n",
      " 22  n_months_last_bought_products      17992 non-null  int64  \n",
      " 23  flg_latest_being_lapse             17992 non-null  int64  \n",
      " 24  flg_latest_being_cancel            17992 non-null  int64  \n",
      " 25  recency_lapse                      17992 non-null  float64\n",
      " 26  recency_cancel                     17992 non-null  float64\n",
      " 27  tot_inforce_pols                   17992 non-null  int64  \n",
      " 28  tot_cancel_pols                    17992 non-null  float64\n",
      " 29  f_hold_839f8a                      17992 non-null  int64  \n",
      " 30  f_hold_e22a6a                      17992 non-null  int64  \n",
      " 31  f_hold_d0adeb                      17992 non-null  int64  \n",
      " 32  f_hold_c4bda5                      17992 non-null  int64  \n",
      " 33  f_hold_ltc                         17992 non-null  int64  \n",
      " 34  f_hold_507c37                      17992 non-null  int64  \n",
      " 35  f_hold_gi                          17992 non-null  int64  \n",
      " 36  f_ever_bought_839f8a               17992 non-null  int64  \n",
      " 37  f_ever_bought_e22a6a               17992 non-null  int64  \n",
      " 38  f_ever_bought_d0adeb               17992 non-null  int64  \n",
      " 39  f_ever_bought_c4bda5               17992 non-null  int64  \n",
      " 40  f_ever_bought_ltc                  17992 non-null  int64  \n",
      " 41  f_ever_bought_507c37               17992 non-null  int64  \n",
      " 42  f_ever_bought_gi                   17992 non-null  int64  \n",
      " 43  f_ever_bought_ltc_1280bf           17992 non-null  int64  \n",
      " 44  f_ever_bought_grp_6fc3e6           17992 non-null  int64  \n",
      " 45  f_ever_bought_grp_de05ae           17992 non-null  int64  \n",
      " 46  f_ever_bought_inv_dcd836           17992 non-null  int64  \n",
      " 47  f_ever_bought_grp_945b5a           17992 non-null  int64  \n",
      " 48  f_ever_bought_grp_6a5788           17992 non-null  int64  \n",
      " 49  f_ever_bought_ltc_43b9d5           17992 non-null  int64  \n",
      " 50  f_ever_bought_grp_9cdedf           17992 non-null  int64  \n",
      " 51  f_ever_bought_lh_d0adeb            17992 non-null  int64  \n",
      " 52  f_ever_bought_grp_1581d7           17992 non-null  int64  \n",
      " 53  f_ever_bought_grp_22decf           17992 non-null  int64  \n",
      " 54  f_ever_bought_lh_507c37            17992 non-null  int64  \n",
      " 55  f_ever_bought_lh_839f8a            17992 non-null  int64  \n",
      " 56  f_ever_bought_inv_e9f316           17992 non-null  int64  \n",
      " 57  f_ever_bought_grp_caa6ff           17992 non-null  int64  \n",
      " 58  f_ever_bought_grp_fd3bfb           17992 non-null  int64  \n",
      " 59  f_ever_bought_lh_e22a6a            17992 non-null  int64  \n",
      " 60  f_ever_bought_grp_70e1dd           17992 non-null  int64  \n",
      " 61  f_ever_bought_grp_e04c3a           17992 non-null  int64  \n",
      " 62  f_ever_bought_grp_fe5fb8           17992 non-null  int64  \n",
      " 63  f_ever_bought_grp_94baec           17992 non-null  int64  \n",
      " 64  f_ever_bought_grp_e91421           17992 non-null  int64  \n",
      " 65  f_ever_bought_lh_f852af            17992 non-null  int64  \n",
      " 66  f_ever_bought_lh_947b15            17992 non-null  int64  \n",
      " 67  f_ever_bought_32c74c               17992 non-null  int64  \n",
      " 68  f_elx                              17992 non-null  int64  \n",
      " 69  f_mindef_mha                       17992 non-null  int64  \n",
      " 70  f_retail                           17992 non-null  int64  \n",
      " 71  flg_affconnect_show_interest_ever  17992 non-null  float64\n",
      " 72  flg_affconnect_ready_to_buy_ever   17992 non-null  float64\n",
      " 73  flg_affconnect_lapse_ever          17992 non-null  float64\n",
      " 74  affcon_visit_days                  17992 non-null  float64\n",
      " 75  n_months_since_visit_affcon        17992 non-null  float64\n",
      " 76  clmcon_visit_days                  17992 non-null  float64\n",
      " 77  recency_clmcon                     17992 non-null  float64\n",
      " 78  recency_clmcon_regis               17992 non-null  float64\n",
      " 79  recency_hlthclaim                  17992 non-null  float64\n",
      " 80  hlthclaim_cnt_success              17992 non-null  float64\n",
      " 81  recency_hlthclaim_success          17992 non-null  float64\n",
      " 82  hlthclaim_cnt_unsuccess            17992 non-null  float64\n",
      " 83  recency_hlthclaim_unsuccess        17992 non-null  float64\n",
      " 84  flg_hlthclaim_839f8a_ever          17992 non-null  float64\n",
      " 85  recency_hlthclaim_839f8a           17992 non-null  float64\n",
      " 86  flg_hlthclaim_14cb37_ever          17992 non-null  float64\n",
      " 87  recency_hlthclaim_14cb37           17992 non-null  float64\n",
      " 88  recency_giclaim                    17992 non-null  float64\n",
      " 89  f_purchase_lh                      17992 non-null  float64\n",
      "dtypes: float64(44), int64(46)\n",
      "memory usage: 12.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flg_substandard               0\n",
       "flg_is_borderline_standard    0\n",
       "flg_is_revised_term           0\n",
       "flg_is_rental_flat            0\n",
       "flg_has_health_claim          0\n",
       "                             ..\n",
       "recency_hlthclaim_839f8a      0\n",
       "flg_hlthclaim_14cb37_ever     0\n",
       "recency_hlthclaim_14cb37      0\n",
       "recency_giclaim               0\n",
       "f_purchase_lh                 0\n",
       "Length: 90, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE to balance the dataset\n",
    "### If you encounter ImportError, please run the following commands:\n",
    "#### pip uninstall scikit-learn\n",
    "#### pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Hanrui\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, RandomOverSampler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m X_train_base, X_test_base, y_train_base, y_test_base \u001b[38;5;241m=\u001b[39m train_test_split(X_base, y_base, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.20\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Hanrui\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size = 0.20, random_state = 42)\n",
    "\n",
    "def balancing(X,y,type):\n",
    "       '''\n",
    "       This function helps us to choose the type of resampling that we \n",
    "       want to do, functional abstraction, 1010 things :-)\n",
    "       '''\n",
    "       ros = RandomOverSampler(random_state=42)\n",
    "       smote = SMOTE(random_state=42)\n",
    "       if type == 'oversample':\n",
    "              return ros.fit_resample(X, y)\n",
    "       else:\n",
    "              return smote.fit_resample(X,y)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Balance the training data \n",
    "X_train , y_train = balancing(X_train , y_train, 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
